{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport keras\nimport os\nimport pandas as pd \nfrom keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D \nfrom tensorflow.keras.layers import MaxPool2D, Flatten, Dense \nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import Model\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer, Conv2DTranspose, UpSampling2D, Concatenate\nfrom tensorflow.keras.optimizers import RMSprop,Adam","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-10T22:38:46.292175Z","iopub.execute_input":"2022-01-10T22:38:46.292839Z","iopub.status.idle":"2022-01-10T22:38:51.534301Z","shell.execute_reply.started":"2022-01-10T22:38:46.292801Z","shell.execute_reply":"2022-01-10T22:38:51.533589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loading data","metadata":{}},{"cell_type":"code","source":"training_images = []\ntraining_groundTruth = []\nvalidation_images = []\nvalidation_groundTruth = []\ntest_images = []\ntest_groundTruth = []\n\npath = \"../input/isic2017-256x256-jpeg/ISIC_2017_256x256/train/images/images\"\npaths = os.listdir(path)\npaths.sort()\nfor image in paths:\n  img = cv2.imread(path + '/' + image)\n  training_images.append(img)\n    \npath = \"../input/isic2017-256x256-jpeg/ISIC_2017_256x256/train/masks/masks\"\npaths = os.listdir(path)\npaths.sort()\nfor image in paths:\n  img = cv2.imread(path + '/' + image)\n  training_groundTruth.append(img)\n    \npath = \"../input/isic2017-256x256-jpeg/ISIC_2017_256x256/valid/images/images\"\npaths = os.listdir(path)\npaths.sort()\nfor image in paths:\n  img = cv2.imread(path + '/' + image)\n  validation_images.append(img)\n    \npath = \"../input/isic2017-256x256-jpeg/ISIC_2017_256x256/valid/masks/masks\"\npaths = os.listdir(path)\npaths.sort()\nfor image in paths:\n  img = cv2.imread(path + '/' + image)\n  validation_groundTruth.append(img)\n    \npath = \"../input/isic2017-256x256-jpeg/ISIC_2017_256x256/test/images/images\"\npaths = os.listdir(path)\npaths.sort()\nfor image in paths:\n  img = cv2.imread(path + '/' + image)\n  test_images.append(img)\n    \npath = \"../input/isic2017-256x256-jpeg/ISIC_2017_256x256/test/masks/masks\"\npaths = os.listdir(path)\npaths.sort()\nfor image in paths:\n  img = cv2.imread(path + '/' + image)\n  test_groundTruth.append(img)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T22:38:51.536777Z","iopub.execute_input":"2022-01-10T22:38:51.538668Z","iopub.status.idle":"2022-01-10T22:39:25.433219Z","shell.execute_reply.started":"2022-01-10T22:38:51.537888Z","shell.execute_reply":"2022-01-10T22:39:25.432475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_images = np.array(training_images)\ntraining_groundTruth = np.array(training_groundTruth)\nvalidation_images = np.array(validation_images)\nvalidation_groundTruth = np.array(validation_groundTruth)\ntest_images = np.array(test_images)\ntest_groundTruth = np.array(test_groundTruth)\ntraining_images.sort()\ntraining_groundTruth.sort()\ninput_shape = training_images[0].shape\nprint(input_shape)\nprint(training_groundTruth.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T22:39:25.43626Z","iopub.execute_input":"2022-01-10T22:39:25.436448Z","iopub.status.idle":"2022-01-10T22:39:29.091998Z","shell.execute_reply.started":"2022-01-10T22:39:25.436424Z","shell.execute_reply":"2022-01-10T22:39:29.091269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image samples","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,9))\nplt.subplot(2,4,1)\nplt.imshow(cv2.cvtColor(training_images[0], cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,2)\nplt.imshow(cv2.cvtColor(training_images[55], cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,3)\nplt.imshow(cv2.cvtColor(training_images[130], cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,4)\nplt.imshow(cv2.cvtColor(training_images[255], cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,5)\nplt.imshow(cv2.cvtColor(training_images[512], cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,6)\nplt.imshow(cv2.cvtColor(training_images[1024], cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,7)\nplt.imshow(cv2.cvtColor(training_images[1350], cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,8)\nplt.imshow(cv2.cvtColor(training_images[1890], cv2.COLOR_BGR2RGB))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T22:39:29.093903Z","iopub.execute_input":"2022-01-10T22:39:29.09423Z","iopub.status.idle":"2022-01-10T22:39:30.577503Z","shell.execute_reply.started":"2022-01-10T22:39:29.094191Z","shell.execute_reply":"2022-01-10T22:39:30.576262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image masks","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,9))\nplt.subplot(2,4,1)\nplt.imshow(training_groundTruth[0], cmap = plt.cm.binary_r)\nplt.subplot(2,4,2)\nplt.imshow(training_groundTruth[55], cmap = plt.cm.binary_r)\nplt.subplot(2,4,3)\nplt.imshow(training_groundTruth[130], cmap = plt.cm.binary_r)\nplt.subplot(2,4,4)\nplt.imshow(training_groundTruth[255], cmap = plt.cm.binary_r)\nplt.subplot(2,4,5)\nplt.imshow(training_groundTruth[512], cmap = plt.cm.binary_r)\nplt.subplot(2,4,6)\nplt.imshow(training_groundTruth[1024], cmap = plt.cm.binary_r)\nplt.subplot(2,4,7)\nplt.imshow(training_groundTruth[1350], cmap = plt.cm.binary_r)\nplt.subplot(2,4,8)\nplt.imshow(training_groundTruth[1890], cmap = plt.cm.binary_r)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T22:39:30.578486Z","iopub.execute_input":"2022-01-10T22:39:30.57873Z","iopub.status.idle":"2022-01-10T22:39:31.479035Z","shell.execute_reply.started":"2022-01-10T22:39:30.578701Z","shell.execute_reply":"2022-01-10T22:39:31.478402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Unet architecture","metadata":{}},{"cell_type":"code","source":"def conv_block(input, num_filters):\n    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    return x\n\ndef encoder_block(input, num_filters):\n    x = conv_block(input, num_filters)\n    p = MaxPool2D((2, 2))(x)\n    return x, p\n\ndef decoder_block(input, skip_features, num_filters):\n    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x\n\ndef build_unet(input_shape):\n    inputs = Input(input_shape)\n\n    s1, p1 = encoder_block(inputs, 64)\n    s2, p2 = encoder_block(p1, 128)\n    s3, p3 = encoder_block(p2, 256)\n    s4, p4 = encoder_block(p3, 512)\n\n    b1 = conv_block(p4, 1024)\n\n    d1 = decoder_block(b1, s4, 512)\n    d2 = decoder_block(d1, s3, 256)\n    d3 = decoder_block(d2, s2, 128)\n    d4 = decoder_block(d3, s1, 64)\n\n    outputs = Conv2D(filters=3, kernel_size=(1,1), padding=\"same\", activation=\"sigmoid\")(d4)\n\n    model = Model(inputs, outputs, name=\"U-Net\")\n    return model\nif __name__ == \"__main__\":\n    input_shape = (256, 256, 3)\n    model = build_unet(input_shape)\n    model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-10T22:42:24.712938Z","iopub.execute_input":"2022-01-10T22:42:24.713206Z","iopub.status.idle":"2022-01-10T22:42:25.106831Z","shell.execute_reply.started":"2022-01-10T22:42:24.713177Z","shell.execute_reply":"2022-01-10T22:42:25.106142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loss and metrics","metadata":{}},{"cell_type":"code","source":"from keras import backend as K\n\n# def IoU(y_true, y_pred, smooth=1):\n#     y_true = K.flatten(y_true)\n#     y_pred = K.flatten(y_pred)\n#     intersection = K.sum(y_true * y_pred)\n#     total = K.sum(y_true + y_pred)\n#     union = total - intersection\n#     IoU = (intersection + smooth)/(union + smooth)\n#     return  IoU\n\ndef IoU(y_true, y_pred, smooth=1):\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    intersection = K.sum(y_true * y_pred)\n    total = K.sum(y_true + y_pred)\n    union = total - intersection\n    IoU = (intersection + smooth)/(union + smooth)\n    return  IoU\n\ndef jaccard_similarity(y_true, y_pred, smooth=1):\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n#     y_true = K.flatten(y_true)\n#     y_pred = K.flatten(y_pred)\n    intersection = K.sum(y_true * y_pred)\n    total = K.sum(y_true + y_pred)\n    union = total - intersection\n    IoU = (intersection + smooth)/(union + smooth)\n    return 1 - IoU\n\ndef jacc_loss(y_true, y_pred):\n     return 1-IoU(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T22:39:34.142882Z","iopub.execute_input":"2022-01-10T22:39:34.14311Z","iopub.status.idle":"2022-01-10T22:39:34.151607Z","shell.execute_reply.started":"2022-01-10T22:39:34.143078Z","shell.execute_reply":"2022-01-10T22:39:34.15064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training network","metadata":{}},{"cell_type":"code","source":"model.compile(loss=[jaccard_similarity],\n                   optimizer=Adam(learning_rate=1e-4),\n                   metrics=[IoU])\n\nresult = model.fit(training_images,training_groundTruth.astype(np.float32),\n                    validation_data=(validation_images, validation_groundTruth.astype(np.float32)),\n                    batch_size=24,\n                    epochs=5,\n                    verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T22:42:44.019079Z","iopub.execute_input":"2022-01-10T22:42:44.019337Z","iopub.status.idle":"2022-01-10T22:47:32.193605Z","shell.execute_reply.started":"2022-01-10T22:42:44.019308Z","shell.execute_reply":"2022-01-10T22:47:32.192897Z"},"trusted":true},"execution_count":null,"outputs":[]}]}