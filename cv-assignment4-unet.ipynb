{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport keras\nimport os\nimport pandas as pd \nfrom keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D \nfrom tensorflow.keras.layers import MaxPool2D, Flatten, Dense \nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import Model\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer, Conv2DTranspose, UpSampling2D, Concatenate\nfrom tensorflow.keras.optimizers import RMSprop,Adam","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-10T22:13:51.244289Z","iopub.execute_input":"2022-01-10T22:13:51.245117Z","iopub.status.idle":"2022-01-10T22:13:55.991510Z","shell.execute_reply.started":"2022-01-10T22:13:51.245064Z","shell.execute_reply":"2022-01-10T22:13:55.990729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loading data","metadata":{}},{"cell_type":"code","source":"training_images = []\ntraining_groundTruth = []\nvalidation_images = []\nvalidation_groundTruth = []\ntest_images = []\ntest_groundTruth = []\n\npath = \"../input/isic2017-256x256-jpeg/ISIC_2017_256x256/train/images/images\"\npaths = os.listdir(path)\npaths.sort()\nfor image in paths:\n  img = cv2.imread(path + '/' + image)\n  training_images.append(img)\n    \npath = \"../input/isic2017-256x256-jpeg/ISIC_2017_256x256/train/masks/masks\"\npaths = os.listdir(path)\npaths.sort()\nfor image in paths:\n  img = cv2.imread(path + '/' + image)\n  training_groundTruth.append(img)\n    \npath = \"../input/isic2017-256x256-jpeg/ISIC_2017_256x256/valid/images/images\"\npaths = os.listdir(path)\npaths.sort()\nfor image in paths:\n  img = cv2.imread(path + '/' + image)\n  validation_images.append(img)\n    \npath = \"../input/isic2017-256x256-jpeg/ISIC_2017_256x256/valid/masks/masks\"\npaths = os.listdir(path)\npaths.sort()\nfor image in paths:\n  img = cv2.imread(path + '/' + image)\n  validation_groundTruth.append(img)\n    \npath = \"../input/isic2017-256x256-jpeg/ISIC_2017_256x256/test/images/images\"\npaths = os.listdir(path)\npaths.sort()\nfor image in paths:\n  img = cv2.imread(path + '/' + image)\n  test_images.append(img)\n    \npath = \"../input/isic2017-256x256-jpeg/ISIC_2017_256x256/test/masks/masks\"\npaths = os.listdir(path)\npaths.sort()\nfor image in paths:\n  img = cv2.imread(path + '/' + image)\n  test_groundTruth.append(img)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T22:13:55.993261Z","iopub.execute_input":"2022-01-10T22:13:55.993516Z","iopub.status.idle":"2022-01-10T22:14:28.651960Z","shell.execute_reply.started":"2022-01-10T22:13:55.993488Z","shell.execute_reply":"2022-01-10T22:14:28.651053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_images = np.array(training_images)\ntraining_groundTruth = np.array(training_groundTruth)\nvalidation_images = np.array(validation_images)\nvalidation_groundTruth = np.array(validation_groundTruth)\ntest_images = np.array(test_images)\ntest_groundTruth = np.array(test_groundTruth)\ntraining_images.sort()\ntraining_groundTruth.sort()\ninput_shape = training_images[0].shape\nprint(input_shape)\nprint(training_groundTruth.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T22:14:28.654474Z","iopub.execute_input":"2022-01-10T22:14:28.655163Z","iopub.status.idle":"2022-01-10T22:14:32.327231Z","shell.execute_reply.started":"2022-01-10T22:14:28.655120Z","shell.execute_reply":"2022-01-10T22:14:32.326458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image samples","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,9))\nplt.subplot(2,4,1)\nplt.imshow(cv2.cvtColor(training_images[0], cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,2)\nplt.imshow(cv2.cvtColor(training_images[55], cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,3)\nplt.imshow(cv2.cvtColor(training_images[130], cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,4)\nplt.imshow(cv2.cvtColor(training_images[255], cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,5)\nplt.imshow(cv2.cvtColor(training_images[512], cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,6)\nplt.imshow(cv2.cvtColor(training_images[1024], cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,7)\nplt.imshow(cv2.cvtColor(training_images[1350], cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,8)\nplt.imshow(cv2.cvtColor(training_images[1890], cv2.COLOR_BGR2RGB))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T22:14:32.329461Z","iopub.execute_input":"2022-01-10T22:14:32.329741Z","iopub.status.idle":"2022-01-10T22:14:33.574428Z","shell.execute_reply.started":"2022-01-10T22:14:32.329704Z","shell.execute_reply":"2022-01-10T22:14:33.573442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image masks","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,9))\nplt.subplot(2,4,1)\nplt.imshow(training_groundTruth[0], cmap = plt.cm.binary_r)\nplt.subplot(2,4,2)\nplt.imshow(training_groundTruth[55], cmap = plt.cm.binary_r)\nplt.subplot(2,4,3)\nplt.imshow(training_groundTruth[130], cmap = plt.cm.binary_r)\nplt.subplot(2,4,4)\nplt.imshow(training_groundTruth[255], cmap = plt.cm.binary_r)\nplt.subplot(2,4,5)\nplt.imshow(training_groundTruth[512], cmap = plt.cm.binary_r)\nplt.subplot(2,4,6)\nplt.imshow(training_groundTruth[1024], cmap = plt.cm.binary_r)\nplt.subplot(2,4,7)\nplt.imshow(training_groundTruth[1350], cmap = plt.cm.binary_r)\nplt.subplot(2,4,8)\nplt.imshow(training_groundTruth[1890], cmap = plt.cm.binary_r)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T22:14:33.575511Z","iopub.execute_input":"2022-01-10T22:14:33.575758Z","iopub.status.idle":"2022-01-10T22:14:34.464130Z","shell.execute_reply.started":"2022-01-10T22:14:33.575727Z","shell.execute_reply":"2022-01-10T22:14:34.463416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Unet architecture","metadata":{}},{"cell_type":"code","source":"def conv_block(input, num_filters):\n    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    return x\n\ndef encoder_block(input, num_filters):\n    x = conv_block(input, num_filters)\n    p = MaxPool2D((2, 2))(x)\n    return x, p\n\ndef decoder_block(input, skip_features, num_filters):\n    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x\n\ndef build_unet(input_shape):\n    inputs = Input(input_shape)\n\n    s1, p1 = encoder_block(inputs, 64)\n    s2, p2 = encoder_block(p1, 128)\n    s3, p3 = encoder_block(p2, 256)\n    s4, p4 = encoder_block(p3, 512)\n\n    b1 = conv_block(p4, 1024)\n\n    d1 = decoder_block(b1, s4, 512)\n    d2 = decoder_block(d1, s3, 256)\n    d3 = decoder_block(d2, s2, 128)\n    d4 = decoder_block(d3, s1, 64)\n\n    outputs = Conv2D(filters=3, kernel_size=(1,1), padding=\"same\", activation=\"sigmoid\")(d4)\n\n    model = Model(inputs, outputs, name=\"U-Net\")\n    return model\nif __name__ == \"__main__\":\n    input_shape = (256, 256, 3)\n    model = build_unet(input_shape)\n    model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-10T22:19:58.443035Z","iopub.execute_input":"2022-01-10T22:19:58.443729Z","iopub.status.idle":"2022-01-10T22:19:58.855623Z","shell.execute_reply.started":"2022-01-10T22:19:58.443672Z","shell.execute_reply":"2022-01-10T22:19:58.854877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loss and metrics","metadata":{}},{"cell_type":"code","source":"from keras import backend as K\n\ndef IoU(y_true, y_pred, smooth=1):\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    intersection = K.sum(y_true * y_pred)\n    total = K.sum(y_true + y_pred)\n    union = total - intersection\n    IoU = (intersection + smooth)/(union + smooth)\n    return  IoU\n\ndef jacc_loss(y_true, y_pred):\n     return 1-IoU(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T22:14:37.304874Z","iopub.execute_input":"2022-01-10T22:14:37.305078Z","iopub.status.idle":"2022-01-10T22:14:37.310396Z","shell.execute_reply.started":"2022-01-10T22:14:37.305052Z","shell.execute_reply":"2022-01-10T22:14:37.309679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training network","metadata":{}},{"cell_type":"code","source":"model.compile(loss=[jacc_loss],\n                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n                   metrics=[IoU])\n\nresult = model.fit(training_images,training_groundTruth.astype(np.float32),\n                    validation_data=(validation_images, validation_groundTruth.astype(np.float32)),\n                    batch_size=24,\n                    epochs=5,\n                    verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T22:23:30.534765Z","iopub.execute_input":"2022-01-10T22:23:30.535419Z"},"trusted":true},"execution_count":null,"outputs":[]}]}